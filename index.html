<!DOCTYPE html>
<html lang="en">

<head>
  <!-- basic
  ========== -->
  <meta charset="utf-8">
  <title>melanie tosik</title>
  <meta name="description" content="Melanie's homie page">
  <meta name="author" content="Melanie Tosik">
  <!-- viewport
  ============= -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- font
  ========= -->
  <link href='https://fonts.googleapis.com/css?family=Playfair+Display:400,700' rel='stylesheet' type='text/css'>
  <!-- favicon
  ============ -->
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
  <!-- CSS
  ======== -->
  <link rel="stylesheet" href="css/style.css" type="text/css">
  <link rel="stylesheet" href="css/normalize.css" type="text/css">
  <link rel="stylesheet" href="css/flexslider.css" type="text/css">
  <!-- JS
  ======= -->
  <script type="text/javascript" src="js/jquery.2.1.3.min.js"></script>
  <script type="text/javascript" src="js/hero.js"></script>
  <script type="text/javascript" src="js/l-by-l.min.js"></script>
  <script src="js/jquery.flexslider.js"></script>
  <!-- carousel
  ============= -->
  <script type="text/javascript" charset="utf-8">
    $(window).load(function() {
      $('.flexslider').flexslider({
        controlNav: true,
        directionNav: false,
        animationLoop: true,
        slideshowSpeed: 10000,
        animationSpeed: 0,
        pauseOnHover: true,
        smoothHeight: false,
      });
    });
  </script>
<!-- analytics
============== -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-50407324-4', 'auto');
    ga('send', 'pageview');
  </script>
</head>

<body>
<!-- hero
========= -->
<section id="hero" class="hero u-full-width" style="height: 100%;">
  <div class="hero-image"></div>
    <div class="container vertical-centered">
      <div class="twelve columns">
        <h1>melanie<sup><em>T</em></sup></h1>
        <h5>Research engineer based in Austin, TX.<br>
        Developing NLP/ML applications.</h5>
        <a class="button hello" href="#hello">More</a>
  </div></div></div>
</section>
<!-- hello
========== -->
<div id="hello" class="container">
  <div class="row">
    <div class="twelve columns">
      <p align="center" class="hello"><code class="msg"></code></p>
</div></div></div>
<!-- intro
========== -->
<div id="intro" class="container">
  <div class="row">
    <div class="twelve columns">
      <p>I'm Melanie. I work to design and implement scalable applications for natural language processing (NLP) and machine learning (ML). I'm currently at <a href="http://www.cognitivescale.com/">CognitiveScale</a>, where I focus on generating personalized recommendations from natural language queries.</p>
</div></div></div>

<!-- retro
========== -->
<div id="retro" class="container">
  <div class="row">
   <div class="twelve columns">
    <p>2015 retrospect! (Let's just keep pretending that 2016 never happened.)
      <ul class="checkmark">
        <li>Write a thesis</li>
        <li>Publish a paper</li>
        <li>Graduate</li>
        <li>Travel</li>
        <li>Go West</li>
        <li>Join a tech startup</li>
        <li>Science&trade;</li>
      </ul></p>
    <p>Turns out I actually <em>did</em> get a lot of stuff done, who would've thought. Lists are good; I recommend you make one yourself.</p>
</div></div></div>

<!-- P vs NP
============ -->
<div id="pvsnp" class="container">
  <div class="row">
   <div class="twelve columns">
   <p><a href="https://www.youtube.com/watch?v=YX40hbAHx3s">P vs. NP and the Computational Complexity Zoo!</a></p>
</div></div></div>

<!-- Blogs
========== -->
<div id="blogs" class="container">
  <div class="row">
   <div class="twelve columns">
   <p>Also everyone has been asking about which tech blogs to keep an eye on recently, so I finally decided to make, you might have guessed it, another list! <a href="http://melanietosik.github.io/blogs.html">Here it is.</a></p>
</div></div></div>

<!-- projects
============= -->
<div id="projects" class="container">
  <div class="row">
    <div class="twelve columns">
      <p>See below for more details on previous projects.</p>
      <div class="flexslider">
        <ul class="slides">
          <li>
            <p class="pro">
              <strong>Edit distances and sequence alignment</strong><br>
              During my senior year, I finally took a class on advanced C++. Surprisingly enough, it didn't seem nearly as hard as the first one I had to struggle through a few years ago, and I ended up having a lot of fun with it.
              As final project, I decided to work on edit distances, and implemented the <a href="https://en.wikipedia.org/wiki/Wagner%E2%80%93Fischer_algorithm">Wagnerâ€“Fischer algorithm</a> as an instance of dynamic programming. Later on, I expanded the project to also cover the <a href="https://en.wikipedia.org/wiki/Needleman%E2%80%93Wunsch_algorithm">Needleman-Wunsch algorithm</a> for global sequence alignment.<br><br>
              <a class="button" href="https://github.com/melanietosik/cpp2/tree/master/sda">Code</a>
            </p>
          </li>
          <li>
            <p class="pro">
              <strong>Semantic Role Labeling using linear-chain CRF</strong><br>
              My very last undergrad project for a class on advanced language modeling, where we discussed the theoretical foundations of <a href="https://en.wikipedia.org/wiki/Hidden_Markov_model">hidden Markov models</a>, the <a href="https://en.wikipedia.org/wiki/Viterbi_algorithm">Viterbi</a> and <a href="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm">EM algorithm</a>, <a href="https://en.wikipedia.org/wiki/Log-linear_model">log-linear models</a>, <a href="https://en.wikipedia.org/wiki/Principle_of_maximum_entropy#Maximum_entropy_models">maximum entropy models</a> (MEMMs), and as well as <a href="https://en.wikipedia.org/wiki/Conditional_random_field">conditional random fields</a> (CRFs).
              <br><br>
              <a class="button" href="files/srl.pdf">Paper</a>
              <a class="button" href="https://github.com/melanietosik/srl">Code</a>
            </p>
          </li>
          <li>
            <p class="pro">
              <strong>String to semantic graph alignment</strong><br>
              For my undergrad thesis, I started working on semantic parsing: the problem of mapping natural language strings to meaning representations. In order to train a semantic parser for English into <a href="https://www.amr.isi.edu/">Abstract Meaning Representation</a>, we first need to know which phrases in the input sentence invoked which concepts in the corresponding AMR graph. The project aimed at building an English/AMR aligner to solve this task automatically.
              <br><br>
              <a class="button" href="http://www.isi.edu/natural-language/mt/amr_eng_align.pdf">Origin</a>
              <a class="button" href="files/thesis.pdf">Thesis</a>
              <a class="button" href="http://github.com/melanietosik/thesis_code">Code</a>
            </p>
          </li>
          <li>
            <p class="pro">
              <strong>Semantic dependency graph parsing</strong><br>
              For a class on semantic dependency graph parsing, I wrote a short script that computes statistics for semantic dependency graphs and generates plots for the distribution of words per <a href="http://en.wikipedia.org/wiki/Directed_graph#Indegree_and_outdegree">indegree and outdegree</a>. As final project, I submitted a comprehensive review on <a href="http://amr.isi.edu/">Abstract Meaning Representation</a> (AMR), a set of English sentences paired with simple, readable semantic representations.
              <br><br>
              <a class="button" href="files/amr.pdf">Paper</a>
              <a class="button" href="https://github.com/melanietosik/dp1">Code</a>
            </p>
          </li>
          <li>
            <p class="pro">
              <strong>Research internship at Textkernel</strong><br>
              In 2014, I was a research intern at <a href="http://www.textkernel.com/">Textkernel</a>, where we explored new methods of improving resume parsing for multi-lingual documents.
              In order to extract structured information in the form of specific phrases like name or address, we adopted the probabilistic <a href="http://en.wikipedia.org/wiki/Conditional_random_field">conditional random fields</a> (CRF) framework. In addition, we experimented with a novel approach that integrates <a href="https://code.google.com/p/word2vec/">continuous vector representations</a> of words as input features for such a model.
              <br><br>
              <a class="button" href="files/report_tosik_textkernel.pdf">Report</a>
              <a class="button" href="http://www.aclweb.org/anthology/W15-1517">Paper</a>
              <!-- <a class="button" href="files/vsm_poster.pdf">Poster</a> -->
              <a class="button" href="http://www.textkernel.com/2014/12/internships-at-textkernel-melanie-tosik/">Interview</a>
            </p>
          </li>
          <li>
            <p class="pro">
              <strong>Word meaning in context</strong><br>
              For a really great class on <a href="http://en.wikipedia.org/wiki/Distributional_semantics">distributional semantics</a>, I presented a paper on &lsquo;Measuring Distributional Similarity in Context&rsquo; (<a href="http://www.aclweb.org/anthology/D10-1113">Dinu and Lapata, 2003</a>).
              In a nutshell, they attempt to model the intuition that word meaning is represented as a probability distribution over a set of latent senses, and thus modulated by context. They employ two different models: the first based on <a href="http://en.wikipedia.org/wiki/Non-negative_matrix_factorization">non-negative matrix factorization</a> (NMF), and the second implementing <a href="http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">Latent Dirichlet Allocation</a> (LDA).
              <br><br>
              <a class="button" href="files/dist_sem.pdf">Paper</a>
              <a class="button" href="files/dinulapata.pdf">Slides</a>
            </p>
          </li>
          <li>
            <p class="pro">
              <strong>Lexical semantics</strong><br>
              I studied abroad and <a href="http://www.socsci.ulster.ac.uk/irss/linguistics.html">learned some linguistics</a>:<br>
                <em style="padding: .5em; display: inline-block;">Consider an example where a zombie has died and been reanimated, and John drowns him.</em><br>
            Presentation slides may or may not help to understand what is going on.
              <br><br>
              <a class="button" href="files/beavers.pdf">Slides</a>
            </p>
          </li>
          <li>
            <p class="pro">
              <strong>Word similarity</strong><br>
              Shortly after I learned that computational semantics is a thing, I implemented word similarity according to <a href="files/lin.pdf">Dekang Lin (1998)</a>.
              <br><br>
              <a class="button" href="http://github.com/melanietosik/linsim">Code</a>
            </p>
          </li>
          <li>
            <p class="pro">
              <strong>Sentence comprehension</strong><br>
              I took some classes on <a href="http://www.uni-potsdam.de/humfak/hum-forschungsschwerpunkte/forschungscluster-sprache.html">psycholinguistics</a>, where I presented a range of interesting papers, including &lsquo;Expectation-based syntactic comprehension&rsquo; (<a href="http://idiom.ucsd.edu/~rlevy/papers/levy-2008-cognition.pdf">Levy, 2008</a>), and &lsquo;Dependency Locality Theory&rsquo; (DLT) (<a href="http://tedlab.mit.edu/tedlab_website/researchpapers/Gibson_2000_DLT.pdf">Gibson, 2000</a>). Check out the slides below!
              <br><br>
              <a class="button" href="files/levy.pdf">Levy</a>
              <a class="button" href="files/gibson.pdf">Gibson</a>
            </p>
          </li>
        </ul>
</div></div></div></div>

<!-- social
=========== -->
<div id="social" class="container">
  <div class="row">
    <div class="three columns">
      <p align="center"><a class="social" href="files/cv_tosik_web.pdf">Resume</a></p>
    </div>
    <div class="three columns">
      <p align="center"><a class="social" href="mailto:melanie.tosik@gmail.com">E-Mail</a></p>
    </div>
    <div class="three columns">
      <p align="center"><a class="social" href="https://github.com/melanietosik">GitHub</a></p>
    </div>
    <div class="three columns">
      <p align="center"><a class="social" href="https://www.linkedin.com/in/melanietosik">LinkedIn</a></p>
    </div>
</div></div>

</body>
</html>
